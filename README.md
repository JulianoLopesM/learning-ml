# Cronograma de Estudos para Machine Learning (8 Semanas)  

Este reposit√≥rio cont√©m um plano detalhado de estudos para aprender Machine Learning em 8 semanas, com foco em teoria, pr√°tica e exerc√≠cios.  

## Sum√°rio  
- [Semana 1: Introdu√ß√£o ao Machine Learning](#semana-1-introdu√ß√£o-ao-machine-learning)  
- [Semana 2: Prepara√ß√£o de Dados](#semana-2-prepara√ß√£o-de-dados)  
- [Semana 3: Algoritmos de Machine Learning - Supervis√£o](#semana-3-algoritmos-de-machine-learning---supervis√£o)  
- [Semana 4: Algoritmos de Machine Learning - N√£o Supervis√£o](#semana-4-algoritmos-de-machine-learning---n√£o-supervis√£o)  
- [Semana 5: Redes Neurais e Deep Learning](#semana-5-redes-neurais-e-deep-learning)  
- [Semana 6: Aprendizado por Refor√ßo](#semana-6-aprendizado-por-refor√ßo)  
- [Semana 7: Avalia√ß√£o e Otimiza√ß√£o](#semana-7-avalia√ß√£o-e-otimiza√ß√£o)  
- [Semana 8: Projeto Final e Pr√≥ximos Passos](#semana-8-projeto-final-e-pr√≥ximos-passos)  

---

## Semana 1: Introdu√ß√£o ao Machine Learning  

### **Teoria (1h)**  
- O que √© Machine Learning e sua import√¢ncia em diferentes √°reas.  
- Tipos de aprendizado: supervisionado, n√£o supervisionado e por refor√ßo.  
- Componentes principais: dados, modelos, treinamento, valida√ß√£o e teste.  
- Ferramentas e bibliotecas populares: Python, NumPy, pandas, scikit-learn, TensorFlow, PyTorch.  

### **Pr√°tica (1h)**  
- Instalar ferramentas b√°sicas: Python, Jupyter Notebook, e bibliotecas como NumPy, pandas e scikit-learn.  
- Explorar um conjunto de dados simples (ex: Titanic ou Iris) com pandas.  
- Criar gr√°ficos b√°sicos com Matplotlib ou Seaborn.  

### **Exerc√≠cio**  
- Analisar estat√≠sticas descritivas do dataset Iris usando pandas e criar gr√°ficos de dispers√£o para entender rela√ß√µes entre vari√°veis.  

---

## Semana 2: Prepara√ß√£o de Dados  

### **Teoria (1h)**  
- A import√¢ncia da qualidade dos dados.  
- Processos de pr√©-processamento: limpeza, normaliza√ß√£o, transforma√ß√£o e redu√ß√£o de dimensionalidade.  
- Divis√£o de dados em conjuntos de treino, valida√ß√£o e teste.  

### **Pr√°tica (1h)**  
- Limpar dados com pandas: lidar com valores ausentes e duplicados.  
- Escalar e normalizar dados com scikit-learn.  
- Dividir um conjunto de dados em treino/teste usando `train_test_split`.  

### **Exerc√≠cio**  
- Carregar o dataset Titanic, tratar valores ausentes e normalizar vari√°veis num√©ricas.  

---

## Semana 3: Algoritmos de Machine Learning - Supervis√£o  

### **Teoria (1h)**  
- Algoritmos supervisionados comuns: regress√£o linear, regress√£o log√≠stica, √°rvores de decis√£o, e SVM.  
- M√©tricas de avalia√ß√£o: accuracy, precision, recall, F1-score, RMSE.  

### **Pr√°tica (1h)**  
- Treinar um modelo de regress√£o linear em dados simples (ex: pre√ßo de casas).  
- Treinar um modelo de classifica√ß√£o com regress√£o log√≠stica no dataset Iris.  
- Avaliar modelos usando `cross_val_score` e relat√≥rios de classifica√ß√£o.  

### **Exerc√≠cio**  
- Criar um modelo de √°rvore de decis√£o para prever a sobreviv√™ncia no Titanic, avaliar e interpretar os resultados.  

---

## Semana 4: Algoritmos de Machine Learning - N√£o Supervis√£o  

### **Teoria (1h)**  
- Introdu√ß√£o ao aprendizado n√£o supervisionado: clustering e redu√ß√£o de dimensionalidade.  
- Algoritmos comuns: K-Means, DBSCAN, PCA.  

### **Pr√°tica (1h)**  
- Aplicar K-Means para agrupar dados do dataset Iris.  
- Reduzir dimensionalidade com PCA e visualizar os resultados.  

### **Exerc√≠cio**  
- Implementar K-Means em um conjunto de dados desconhecido e analisar os clusters formados.  

---

## Semana 5: Redes Neurais e Deep Learning  

### **Teoria (1h)**  
- O que s√£o redes neurais artificiais (ANNs).  
- Estrutura b√°sica: neur√¥nios, camadas, fun√ß√µes de ativa√ß√£o e perda.  
- Introdu√ß√£o ao TensorFlow e Keras.  

### **Pr√°tica (1h)**  
- Construir e treinar uma rede neural simples em TensorFlow/Keras para classifica√ß√£o de d√≠gitos (MNIST).  
- Avaliar o modelo e ajustar hiperpar√¢metros b√°sicos.  

### **Exerc√≠cio**  
- Construir uma rede neural para prever se uma pessoa sobreviveu no Titanic.  

---

## Semana 6: Aprendizado por Refor√ßo  

### **Teoria (1h)**  
- Introdu√ß√£o ao aprendizado por refor√ßo: agentes, estados, a√ß√µes e recompensas.  
- Conceitos b√°sicos: Q-Learning, redes neurais profundas no aprendizado por refor√ßo (DQN).  

### **Pr√°tica (1h)**  
- Implementar um agente simples com Q-Learning para resolver o problema do "Frozen Lake" no OpenAI Gym.  
- Explorar o impacto de par√¢metros como taxa de aprendizado e fator de desconto.  

### **Exerc√≠cio**  
- Treinar um agente que jogue "CartPole" usando o OpenAI Gym.  

---

## Semana 7: Avalia√ß√£o e Otimiza√ß√£o  

### **Teoria (1h)**  
- T√©cnicas de avalia√ß√£o: valida√ß√£o cruzada, curva ROC, AUC.  
- Otimiza√ß√£o de hiperpar√¢metros com Grid Search e Random Search.  
- Overfitting e t√©cnicas de regulariza√ß√£o.  

### **Pr√°tica (1h)**  
- Avaliar modelos com curvas ROC e AUC no dataset Titanic.  
- Usar GridSearchCV para encontrar os melhores hiperpar√¢metros de um modelo.  

### **Exerc√≠cio**  
- Ajustar os hiperpar√¢metros de uma √°rvore de decis√£o para maximizar o desempenho.  

---

## Semana 8: Projeto Final e Pr√≥ximos Passos  

### **Teoria (1h)**  
- Boas pr√°ticas no desenvolvimento de projetos de ML.  
- Introdu√ß√£o a MLOps: deploy e monitoramento de modelos.  
- Ferramentas para seguir aprendendo: Kaggle, Papers with Code, e cursos avan√ßados.  

### **Pr√°tica (2h)**  
- Criar um projeto completo:  
  1. Escolher um dataset (ex: Kaggle).  
  2. Analisar, limpar e processar os dados.  
  3. Treinar e avaliar um modelo supervisionado ou n√£o supervisionado.  
  4. Documentar resultados e apresentar insights.  

### **Exerc√≠cio**  
- Publicar o projeto no GitHub e receber feedback da comunidade.  

---

## Dicas Gerais  
1. **Pr√°tica Constante:** Reserve um tempo di√°rio ou semanal para praticar.  
2. **Participa√ß√£o em Comunidades:** Envolva-se em f√≥runs como Stack Overflow, Medium, e Kaggle.  
3. **Estudo Cont√≠nuo:** Explore t√≥picos avan√ßados, como NLP, Vis√£o Computacional e s√©ries temporais.  

Pronto para come√ßar? üöÄ  

